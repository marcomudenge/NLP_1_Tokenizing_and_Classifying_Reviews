{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417a4c65",
   "metadata": {},
   "source": [
    "# INF8460: Traitement automatique de la langue naturelle\n",
    "\n",
    "# TP1: Comparaison d'algorithmes pour classification de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc062396",
   "metadata": {},
   "source": [
    "## Identification de l'équipe:\n",
    "\n",
    "### Groupe de laboratoire: \n",
    "\n",
    "### Equipe numéro : \n",
    "\n",
    "### Membres: \n",
    "\n",
    "- membre 1 (% de contribution, nature de la contribution)\n",
    "- membre 2 (% de contribution, nature de la contribution)\n",
    "- membre 3 (% de contribution, nature de la contribution)\n",
    "\n",
    "* nature de la contribution: Décrivez brièvement ce qui a été fait par chaque membre de l’équipe. Tous les membres sont censés contribuer au développement. Bien que chaque membre puisse effectuer différentes tâches, vous devez vous efforcer d’obtenir une répartition égale du travail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dacaae",
   "metadata": {},
   "source": [
    "\n",
    "## Description:\n",
    "\n",
    "Dans ce premier TP, vous explorerez les bases du traitement automatique du langage naturel. Au cours de ce travail, vous appliquerez concrètement les concepts enseignés en classe pour résoudre une tâche de classification simple. De plus, le processus ressemblera à la manière dont vous aborderiez ce type de problème dans le monde réel. Tout au long de ce laboratoire, vous vous familiariserez avec des bibliothèques couramment utilisées en NLP ainsi qu'en science des données.\n",
    "\n",
    "Dans ce laboratoire, vous travaillerez avec un jeu de données comprenant des évaluations de produits provenant d'Amazon. Pour chaque évaluation, le jeu de données contient trois informations : le titre fourni par l'utilisateur, le commentaire détaillé et le nombre d'étoiles attribué par l'utilisateur au produit.\n",
    "\n",
    "L'objectif de cette tâche consistera à prédire le nombre d'étoiles attribué à une évaluation à partir du commentaire et du titre qui lui sont associés.\n",
    "\n",
    "Le travail sera divisé en 3 parties:\n",
    "\n",
    " - Chargement, prétraitement et visualisation des données: Dans cette première partie, vous allez charger et prétraiter les données afin qu'elles soient prêtes à être utilisées par les algorithmes lors de la deuxième partie.\n",
    " - Classification: Cette partie consistera à explorer les différents algorithmes pouvant être appliqués à cette tâche. Vous ferez aussi une analyse des sorties du classificateur bayésien naïf.\n",
    " - Amélioration de modèle: Cette dernière partie consistera à améliorer votre modèle de 2 façons différentes. D'abord, vous ferez une recherche d'hyper-paramètres avec de la validation croisée en utilisant un GridSearch. Ensuite, vous ferez de l'extraction d'attributs avec l'aide de ChatGPT afin de d'entrainer un nouveau modèle et de comparer ainsi une représentation de type \"Bag of words\" et une représentation avec attributs spécifiques. \n",
    "\n",
    "\n",
    "## Plan du TP\n",
    "\n",
    "1.    [Chargement, prétraitement et visualisation des données](#1)\n",
    "- 1.1   [Charger les données](#1.1)\n",
    " - 1.1.1 [Charger le jeu de données](#1.1.1)\n",
    " - 1.1.2 [Fusionner les colonnes title et text en une seule colonne](#1.1.2)\n",
    "- 1.2   [Prétraitement des données](#1.2)\n",
    "- 1.3   [Visualisation des données](#1.3)\n",
    " - 1.3.1 [Afficher dans un graphique le nombre d'exemples présents dans le jeu de données pour chaque catégorie](#1.3.1)\n",
    " - 1.3.2 [Afficher dans un graphique la quantité moyenne de jetons par exemple selon la catégorie](#1.3.2)\n",
    " - 1.3.3 [Afficher en texte les top 10 jetons les plus fréquents par catégorie](#1.3.3)\n",
    " - 1.3.4 [Afficher en texte les top 10 adjectifs les plus fréquents selon la catégorie](#1.3.4)\n",
    "- 1.4   [Diviser les données en ensembles d'entraînement et de test](#1.4)\n",
    "- 1.5   [Construction du vocabulaire](#1.5)\n",
    "- 1.6   [Vectorisation des données](#1.6)\n",
    "2.    [Classification](#2)\n",
    "- 2.1   [Modèle aléatoire (Random baseline)](#2.1)\n",
    "- 2.2   [Analyse et compréhension d'un classificateur bayésien naïf (NB)](#2.2)\n",
    " - 2.2.1 [Construction du modèle](#2.2.1)\n",
    " - 2.2.2 [Matrice de confusion](#2.2.2)\n",
    " - 2.2.3 [Visualisation des probabilités de NB](#2.2.3)\n",
    " - 2.2.4 [Visualisation des erreurs commises](#2.2.4)\n",
    " - 2.2.5 [Analyse d'erreurs commises](#2.2.5)\n",
    "- 2.3   [Régression logistique](#2.3)\n",
    "- 2.4   [MLP](#2.4)\n",
    "3.    [Amélioration de modèle](#3)\n",
    "- 3.1   [Recherche d'hyper-paramètres et validation croisée](#3.1)\n",
    "- 3.2   [Extraction d'attributs (Feature extraction) avec ChatGPT](#3.2)\n",
    "- 3.3   [Amélioration du modèle en 3.2](#3.3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96c2d5",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1. Chargement, prétraitement et visualisation des données (30 points)\n",
    "\n",
    "Dans cette première partie, vous allez charger et prétraiter les données afin qu'elles soient prêtes à être utilisées par les algorithmes lors de la deuxième partie.\n",
    "\n",
    "<a name='1.1'></a>\n",
    "### 1.1 Charger les données  (2 points)\n",
    "\n",
    "Ce numéro doit être résolu en utilisant la bibliothèque **pandas**.\n",
    "\n",
    "<a name='1.1.1'></a>\n",
    "#### 1.1.1 Charger le jeu de données (1 point)\n",
    "\n",
    "Chargez le jeu de données amazon_rating.csv. Affichez ensuite son contenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ccc645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88767fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aadd4f88",
   "metadata": {},
   "source": [
    "<a name='1.1.2'></a>\n",
    "#### 1.1.2 Fusionner les colonnes title et text en une seule colonne (1 point)\n",
    "\n",
    "Afin de faciliter la tâche pour le reste du TP, nous allons fusionner ces deux colonnes afin que nous n'ayons qu'un seul texte à considérer lors de la vectorisation.\n",
    "\n",
    "Afin de s'assurer de l'intégrité des textes, fusionnez-les à l'aide d'un espace. Par exemple, une évaluation ayant le titre \"Five Stars\" et le commentaire \"good as any name brand\" aura comme texte final \"Five Stars good as any name brand\".\n",
    "\n",
    "Stockez le résultat dans la colonne \"text\" et supprimez la colonne \"title\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b627c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fbcbf38",
   "metadata": {},
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 Prétraitement des données (4 points)\n",
    "\n",
    "En utilisant la librairie nltk, implémentez la fonction suivante qui :\n",
    "\n",
    "- Enlève les majuscules.\n",
    "- Enlève les caractères de ponctuation.\n",
    "- Segmente la séquence en entrée en une liste de jetons (tokenization).\n",
    "- Enlève les \"stopwords\"\n",
    "- Effectue la racinisation.\n",
    "- Retourne l'ensemble des jetons de la séquence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "#lemmer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    \"\"\"\n",
    "    Fonction qui transforme une chaine de caractère en liste de jetons.\n",
    "    Les pre-traitements à implémenter sont: \n",
    "    1. Enlever les majuscules\n",
    "    2. Enlever les caractères de ponctuations\n",
    "    3. Séparer la chaine de caractères en une liste de jetons (tokenization) \n",
    "    4. Enlever les stopwords\n",
    "    5. Stemming (racinisation)\n",
    "    \n",
    "    :param sentence: une chaine de caractère\n",
    "    :return: la liste de jetons\n",
    "    \"\"\" \n",
    "    \n",
    "    # TODO\n",
    "    tokens = None\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NE PAS MODIFIER\n",
    "\n",
    "Le code suivant appliquera votre fonction sur tous les exemples. Il gardera aussi une version originale pour une analyse future.\n",
    "\"\"\"\n",
    "\n",
    "data[\"text_original\"] = data[\"text\"]\n",
    "data[\"text\"] = data[\"text\"].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0e19b",
   "metadata": {},
   "source": [
    "<a name='1.3'></a>\n",
    "### 1.3 Visualisation des données (15 points)\n",
    "\n",
    "**Utilisez la bibliothèque matplotlib pour les graphiques.** Vous pouvez utiliser n'importe quelle classe de base de Python, par exemple collections.Counter, qui sera utile pour l'affichage des jetons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d61c8",
   "metadata": {},
   "source": [
    "La colonne \"rating\" contient le nombre d'étoiles associé à l'évaluation d'un utilisateur. Le nombre d'étoiles varie entre 1 et 5.\n",
    "\n",
    "Afin de simplifier la tâche de classification, nous avons enlevé les commentaires ayant 2 et 4 étoiles du jeu de données. Cela signifie qu'il y a trois catégories de commentaires, c'est-à-dire ceux ayant 1, 3 ou 5 étoiles.\n",
    "\n",
    "Affichez dans un graphique :\n",
    "\n",
    "- Le nombre d'exemples présents dans le jeu de données par catégorie.\n",
    "- La quantité moyenne de jetons par exemple selon la catégorie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e870b33",
   "metadata": {},
   "source": [
    "<a name='1.3.1'></a>\n",
    "#### 1.3.1  Afficher dans un graphique le nombre d'exemples présents dans le jeu de données pour chaque catégorie  (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b4dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244aa72",
   "metadata": {},
   "source": [
    "<a name='1.3.2'></a>\n",
    "#### 1.3.2 Afficher dans un graphique le nombre moyen de jetons dans les exemples de chaque catégorie (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f798a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6650c0f",
   "metadata": {},
   "source": [
    "<a name='1.3.3'></a>\n",
    "#### 1.3.3 Afficher en texte les top 10 des jetons les plus fréquents par catégorie (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff8a3f",
   "metadata": {},
   "source": [
    "\n",
    "Affichez en texte les 10 jetons les plus fréquents selon la catégorie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befd5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb388a",
   "metadata": {},
   "source": [
    "<a name='1.3.4'></a>\n",
    "#### 1.3.4 Afficher en texte les top 10 des adjectifs les plus fréquents selon la catégorie (4 points)\n",
    "\n",
    "Pour cet exercice, vous devrez utiliser la fonction [nltk.pos_tag](https://www.nltk.org/book/ch05.html) et retenir les jetons identifiés comme JJ.\n",
    " \n",
    "Pour obtenir de bons résultats, le tagger [nltk.pos_tag](https://www.nltk.org/book/ch05.html) doit être exécuté sur le texte original, incluant les stopwords. \n",
    "Vous devrez donc partir des évaluations originales. Pour vous simplifier la tâche, utilisez \n",
    "le tokenizer *word_tokenize* provenant de nltk.\n",
    "\n",
    "**Les adjectifs sont les jetons identifiés comme JJ.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de4b1e",
   "metadata": {},
   "source": [
    "<a name='1.4'></a>\n",
    "### 1.4 Diviser les données en ensembles d'entraînement et de test (1 point)\n",
    "\n",
    "À l'aide de la fonction [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de SKlearn, séparez les données en ensembles d'entraînement (67% des données) et de test (33% des données). Gardez les deux ensembles dans 2 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146eabe",
   "metadata": {},
   "source": [
    "<a name='1.5'></a>\n",
    "### 1.5 Construction du vocabulaire (4 points)\n",
    "\n",
    "Dans un modèle Bag-of-Words (BoW), un vocabulaire est prédéterminé à partir de l'ensemble d'entraînement. Seuls les mots faisant partie de ce vocabulaire seront considérés pour la suite.\n",
    "\n",
    "Complétez la fonction **build_voc** qui retourne une liste de jetons qui sont présents au moins n fois (threshold passé en paramètre) dans la liste d'exemples (également passée en paramètre). Vous pouvez utiliser la classe Counter.\n",
    "\n",
    "Ensuite, appelez cette fonction pour construire votre vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e901d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_voc(documents, threshold):\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006f572",
   "metadata": {},
   "source": [
    "<a name='1.6'></a>\n",
    "### 1.6 Vectorisation des données (4 points)\n",
    "\n",
    "À l'aide de la classe [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) de Sklearn, transformez l'ensemble de jetons en matrice de co-occurence utilisant TF-IDF.\n",
    "\n",
    "Utilisez le vocabulaire construit au numéro précédent dans votre matrice de co-occurrence (voir le paramètre vocabulary de TfidfVectorizer). \n",
    "\n",
    "**Faites attention:** Il ne faut pas entrainer (fit) la vectorisation sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00781ca",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2. Classification (35 points)\n",
    "\n",
    "Maintenant que les données sont prêtes à être utilisées par nos modèles, nous allons entrainer et tester différent types de modèles sur le jeu de données afin d'en faire la comparaison. \n",
    "\n",
    "Cette section sera divisé en cinq modèle:\n",
    "   - Modèle aléatoire (Random baseline)\n",
    "   - Classificateur bayésien naïf\n",
    "   - Régression Logistique\n",
    "   - Multi-Layer Perceptron (MLP)\n",
    "\n",
    "<a name='2.1'></a>\n",
    "### 2.1 Modèle aléatoire (Random baseline) (5 points)\n",
    "\n",
    "Un seuil (baseline) est un modèle servant de référence et dont les performances représentent un seuil à dépasser.\n",
    "\n",
    "#### a) Générez ce seuil en effectuant des prédictions aléatoires parmi les valeurs 1, 3 et 5. Ensuite, affichez les mesures de performance : précision, rappel (recall) et F1. Utilisez la classe classification_report de SKlearn et affichez 4 chiffres après la virgule. (3.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc582223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79530a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7070590",
   "metadata": {},
   "source": [
    "#### b) Comment pouvez-vous expliquer le F1-score obtenu? (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86cab6",
   "metadata": {},
   "source": [
    "> *Entrez votre réponse ici*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eadb0d3",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 Analyse et compréhension d'un classificateur bayésien naïf (NB) (22 points)\n",
    "\n",
    "Naive Bayes (NB) est un algorithme très simple pouvant servir de bon point de départ (baseline) pour les tâches de classification. Ce numéro portera sur l'analyse de ce modèle afin de bien comprendre son comportement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04861f",
   "metadata": {},
   "source": [
    "<a name='2.2.1'></a>\n",
    "#### 2.2.1 Construction du modèle (4 points)\n",
    "\n",
    "Commencez d'abord par construire le modèle à l'aide de la classe MultinomialNB de SKlearn. Utilisez les données vectorisées produites en 1.6.\n",
    "\n",
    "Affichez les performances de votre classificateur (précision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90814a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a784a1",
   "metadata": {},
   "source": [
    "<a name='2.2.2'></a>\n",
    "####  2.2.2 Matrice de confusion (3 points)\n",
    "\n",
    "Visualisez la matrice de confusion de votre modèle en utilisant la fonction [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) de seaborn. Celle-ci peut prendre en entrée une matrice de confusion comme celle fournie par la fonction [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) dans SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115ac85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d6c84",
   "metadata": {},
   "source": [
    "<a name='2.2.3'></a>\n",
    "####  2.2.3 Visualisation des probabilités de NB (5 points)\n",
    "\n",
    "Naive Bayes est un classificateur suivant une approche générative. Durant son entraînement, il apprend les probabilités P(x_i|y). En utilisant le théorème de Bayes, on peut exprimer la probabilité d'une classe donnée y étant donné un ensemble de caractéristiques x_1, x_2, ..., x_n comme suit : \n",
    "\n",
    "$$ P(y|x_1, x_2, ..., x_n) = P(y) * P(x_1|y) * P(x_2|y) * ... * P(x_n|y) $$\n",
    "\n",
    "Ainsi, étant donné un exemple ayant le jeton x_i, plus la probabilité P(x_i|y) est élevée pour une classe, plus la probabilité que l'exemple provienne de cette classe augmente.\n",
    "\n",
    "Écrivez du code permettant de visualiser les jetons ayant les plus grandes probabilités selon la classe dans un graphique de type [barh](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.barh.html). Consultez la documentation de [MultiNomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) afin de trouver les probabilités P(x_i|y). Le graphique produit devrait montrer, sur l'axe des Y, les 10 jetons associés au P(x_i|y) le plus grand selon y. L'axe des X devrait représenter la valeur des probabilités.\n",
    "\n",
    "Ce code devra être sous forme d'une fonction où on passe la classe y en paramètre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb219a46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600bf66",
   "metadata": {},
   "source": [
    "Que pouvez-vous remanquer à propos des jetons affichés dans le graphique?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61bab3",
   "metadata": {},
   "source": [
    "> *Entrez votre réponse ici* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00579fba",
   "metadata": {},
   "source": [
    "<a name='2.2.4'></a>\n",
    "#### 2.2.4 Visualisation des erreurs commises  (3 points)\n",
    "\n",
    "Trouvez toutes les phrases dont la vraie valeur est 5 mais la valeur prédite est de 1.\n",
    "\n",
    "Affichez ces exemples d'une manière lisible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fef76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffb9d00",
   "metadata": {},
   "source": [
    "<a name='2.2.5'></a>\n",
    "#### 2.2.5 Analyse d'erreurs commises (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c7fff",
   "metadata": {},
   "source": [
    "Complétez la fonction plot_example qui:\n",
    "   - Prend en entrée une liste de jetons provenant d'un exemple. \n",
    "   - Produit un graphique qui pour chaque jeton, affiche la valeur P(x_i|y=5) et P(x_i|y=1)\n",
    "    \n",
    "**Pour vous faciliter le travail, utiliser barh de pandas et non de matplotlib**: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html\n",
    "\n",
    "\n",
    "#### a) Exécutez votre fonction avec une phrase au choix dont la vraie valeur est 5 mais la valeur prédite est de 1. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0795de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(tokens):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2984273",
   "metadata": {},
   "source": [
    "#### b) Suite à cette analyse, pouvez-vous voir une tendance dans les exemples qui sont prédits comme faisant partie de la classe 1 mais faisant réellement partie de la classe 5 ?  (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cc027",
   "metadata": {},
   "source": [
    "> *Entrez votre réponse ici*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0f9a6",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "### 2.3 Régression logistique (4 points)\n",
    "\n",
    "Entrainez un modèle de [régression logistique](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) à l'aide de SKLearn en utilisant les données produites en 1.6 et affichez sa performance avec les mêmes métriques que précédemment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c91797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0ff9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727658f6",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "### 2.4 MLP (4 points)\n",
    "\n",
    "Entrainez un modèle neuronal de type [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) à l'aide de SKLearn en utilisant les données produites en 1.6. Affichez sa performance avec les mêmes métriques que précédemment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b383b9",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3. Amélioration de modèle (30 points)\n",
    "\n",
    "Cette dernière partie consistera à améliorer votre modèle de deux façons différentes.\n",
    "\n",
    "Tout d'abord, vous effectuerez une recherche d'hyper-paramètres avec une validation croisée en utilisant une grille de recherche (GridSearch). Ensuite, vous réaliserez de l'extraction d'attributs (feature extraction) afin d'entraîner un nouveau modèle.\n",
    "\n",
    "<a name='3.1'></a>\n",
    "###  3.1 Recherche d'hyper-paramètres et validation croisée (5 points)\n",
    "\n",
    "La classe [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) permet d'explorer toutes les combinaisons possibles d'hyper-paramètres que l'on spécifie afin de trouver la configuration optimale. De plus, il est tout à fait possible de fusionner les paramètres du pré-traitement et ceux du classificateur en utilisant la classe [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "Pour la rédaction de votre code, vous avez la possibilité de vous référer au tutoriel du cours.\n",
    "\n",
    "#### a) Dans cette phase, l'objectif est de découvrir une configuration optimale pour le modèle LogisticRegression en conjonction avec la technique de vectorisation TF-IDF. Cette recherche devra être guidée par la métrique du F1-score pondéré (weighted F1). Vous devrez aussi effectuer une exploration de paramètres sur au moins deux attributs liés à TF-IDF et deux paramètres de la régression logistique. Affichez ensuite la performance finale du modèle optimal ainsi que ses paramètres. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1121d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91d718",
   "metadata": {},
   "source": [
    "#### b) Quels sont les attributs que vous avez choisis et quels sont leurs valeurs optimales?  (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b34bc1c",
   "metadata": {},
   "source": [
    "> *Entrez votre réponse ici*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541be45",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "###  3.2 Extraction d'attributs (Feature extraction) avec ChatGPT (15 points)\n",
    "\n",
    "ChatGPT peut être très utile pour donner des idées ou donner du squelette de code (lorsque c'est permis! :) ). Cette partie vous fait explorer l'utilisation de ChatGPT pour générer du code permettant d'extraire des attributs (feature extraction) à partir du texte des évaluations. \n",
    "\n",
    "En utilisant ChatGPT ainsi que votre recherche personnelle, essayez de déterminer un ensemble d'attributs que vous pourriez utiliser pour représenter chaque évaluation. A vous de voir comment vous pouvez obtenir une réponse satisfaisante de ChatGPT. \n",
    "\n",
    "#### a) Indiquez dans la cellule ci-dessous les descriptions d'attributs suggérées par ChatGPT ainsi que les vôtres. Différenciez clairement vos attributs - s'il y en a - de ceux de ChatGPT. (4 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9ac3f",
   "metadata": {},
   "source": [
    "> *Entrez votre réponse ici*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39beb713",
   "metadata": {},
   "source": [
    "#### b) Indiquez ci-dessous le code généré par ChatGPT que vous avez décidé de conserver pour représenter chaque évaluation.  (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a73ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ebb4523",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### c) Il se peut que le code généré ait besoin d'être adapté à notre jeu de données. Si c'est le cas, corrigez le code et montrez le résultat après vos correction dans la cellule ci-dessous. Le code final devrait être une fonction qui vous retourne, pour un document, un dictionnaire d'attributs et leurs valeurs. N'oubliez pas d'indiquer votre propre code s'il y en a. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843cbc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "518c6c20",
   "metadata": {},
   "source": [
    "#### d) Utilisez le code corrigé ci-dessus pour entrainer un modèle MLP avec votre nouvelle représentation des évaluations. Affichez sa performance. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ee1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce4bf76e",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 Amélioration du modèle en 3.2 (10 points)\n",
    "\n",
    "Il est possible que les résultats obtenus au numéro précédent ne soient pas très élevés. \n",
    "\n",
    "#### a) Trouvez une manière d'utiliser ces attributs avec d'autres éléments afin **d'au moins** obtenir une meilleure performance que n'importe quel score obtenu au numéro 2.x , **sans faire de recherche d'hyper-paramètres**. Essayez d'obtenir la meilleure performance possible. Vous êtes libres d'utiliser n'importe quel algorithme de ce laboratoire. Affichez le code et les performances de votre modèle. (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541ae91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785791f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21566d5",
   "metadata": {},
   "source": [
    "#### b) Quelles sont vos conclusions concernant l'utilisation de ChatGPT et les représentations possibles des documents ? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8a8a9",
   "metadata": {},
   "source": [
    "> *Entrez votre réponse ici*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b28b4",
   "metadata": {},
   "source": [
    "## LIVRABLES:\n",
    "Vous devez remettre sur Moodle, avant la date d'échéance, un zip contenant les fichiers suivants :\n",
    "\n",
    "1-\tLe code : Vous devez compléter le squelette inf8460_A23_TP1.ipynb sous le nom   GR0X_equipe_i_inf8460_A23_TP1(X: numéro du groupe de laboratoire; i = votre numéro d’équipe). Indiquez vos noms et matricules au début du notebook. Ce notebook doit contenir les fonctionnalités requises. \n",
    "\n",
    "2-\tUn fichier pdf représentant votre notebook complètement exécuté sous format pdf. \n",
    "Pour créer le fichier cliquez sur File > Download as > PDF via LaTeX (.pdf). Assurez-vous que le PDF est entièrement lisible.\n",
    "\n",
    "\n",
    "## EVALUATION \n",
    "\n",
    "Votre TP sera évalué selon les critères suivants :\n",
    "\n",
    "1. Exécution correcte du code: Tout votre code et vos résultats doivent être exécutables et reproductibles.\n",
    "2. Qualité du code (noms significatifs, structure, gestion d’exception, etc.) avec, entre autres, les recommandations suivantes:\n",
    "    - Il ne devrait pas y avoir de duplication de code. Utilisez des fonctions pour garder votre code modulaire\n",
    "    - Votre code devrait être optimisé: un code trop lent entraînera une perte de points\n",
    "3. Lisibilité du code (Commentaires clairs et informatifs): Le code doit être exécutable sans erreur et accompagné de commentaires appropriés de manière à expliquer les différentes fonctions\n",
    "4. Performance attendue des modèles\n",
    "5. Effort effectué dans la recherche d'autres types d'attributs et dans l'utilisation de ChatGPT\n",
    "6. Réponses correctes/sensées aux questions de réflexion ou d'analyse\n",
    "7. PDF entièrement lisible. Les parties illisibles ne seront pas corrigées et aucune modification passée la date de remise ne sera acceptée.\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
